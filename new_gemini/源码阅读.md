# src

## 1 comm

**负责通信**，包括 request 和 response

### 1.1 comm.h

变量定义：

```c++
typedef int32_t reqid_t;
enum comm_request_t { REQ_QUOTA, REQ_MEM_LIMIT, REQ_MEM_UPDATE };
```

函数：

`template <typename T> T get_msg_data(char *buf, size_t &pos)`：用于从消息缓冲区 buf 中提取数据并返回

`template <typename T> size_t append_msg_data(char *buf, size_t &pos, T data)`：用于将数据 data 添加到消息缓冲区 buf 中

### 1.2 comm.cpp

引用了 `comm.h` 和 `debug.h`

```c++
reqid_t prepare_request(char *buf, comm_request_t type, ...)
```

用于**准备一个通信请求消息**，消息缓冲区为 buf. 函数会获取客户端的名称长度、名称、请求 ID、请求类型 type 添加到 buf，并根据请求类型添加额外信息到 buf

```c++
char *parse_request(char *buf, char **name, size_t *name_len, reqid_t *id, comm_request_t *type)
```

用于**解析通信请求消息**，消息缓冲区为 buf. 从消息中提取客户端名称的长度，名称，请求 ID 和请求类型.

```c++
size_t prepare_response(char *buf, comm_request_t type, reqid_t id, ...)
```

用于**准备一个通信响应消息**，消息缓冲区为 buf. 将请求 ID 添加到消息缓冲区，并根据响应类型添加相应的额外信息.

```c++
char *parse_response(char *buf, reqid_t *id)
```

用于**解析通信响应消息**，消息缓冲区为 buf. 从消息中提取请求 ID，并将其存储在传入的 `id` 指针中

```c++
int multiple_attempt(std::function<int()> func, int max_attempt, int interval)
```

多次尝试执行传入的函数 `func`

- `max_attempt` 是最大尝试次数。
- `interval` 是每次尝试之间的休眠时间（以秒为单位）

## 2 debug

负责输出调试信息

### 2.1 debug.h

`DEBUG`、`INFO`、`WARNING` 和 `ERROR` 四个函数，用于输出不同级别的日志消息。

### 2.2 debug.cpp

```c++
void sprint_date(char *buf, const size_t len)
```

用于生成当前日期和时间的字符串，并将其存储在 `buf` 中

```c++
#define GENERATE_PRINT(func, level)     
```

这个宏用于生成日志输出函数，例如 `DEBUG`、`INFO`、`WARNING` 和 `ERROR`

## 3 hook

目标，**生成用于拦截应用程序的 CUDA 相关函数调用的库**。

这个 hook library 在第一次拦截到函数调用时会**尝试连接到调度系统**。之后，所有的 CUDA 内核启动以及一些与 GPU 内存相关的活动都将由这个 hook library 来控制。

**核心是一堆 prehooks 和 posthooks，执行逻辑是：拦截 CUDA 相关 API，在调用原始函数之前，如果有预处理 hook，则先执行预处理逻辑；调用原始函数后，如果有后处理 hook 并且原始函数调用成功，则执行后处理逻辑。**

### 3.1 hook.h

定义了一个枚举类型 HookSymbols，包含一些枚举值，用于**标识不同的 CUDA 函数或操作**，如内存分配、上下文操作、内核启动等等。共 `NUM_HOOK_SYMBOLS` 个

### 3.2 hook.cpp

**动态链接库函数替换（`dlsym`）**：

- 代码中定义了一个 `dlsym` 函数的版本，用于替换系统的 `dlsym`。它检查传入的符号名称，如果是 CUDA 相关的函数（比如以 "cu" 开头的），则返回一个自定义的函数指针。
- 这允许代码在运行时拦截对这些 CUDA 函数的调用，并将它们重定向到自己的实现中。

**定义了一个 `hookInfo` 结构体**：

+ 其中包含了一些调试模式标志、preHooks、postHooks 和函数调用计数器 call_count。

- 这些 hook 可以在 CUDA 函数调用前后执行自定义的代码，以实现监控或者修改行为。

**网络通信和多线程：**

+ 与 Pod manager 连接，有一个 `pod_manager_port_list` 的 vector
+ 使用了多线程同步机制（例如互斥锁和条件变量）来确保在多线程环境下的安全性。

**GPU 资源管理**：

- 管理了 GPU 的内存分配和计时信息，包括使用预测器来预估 GPU 的负载。
- 实现了对 GPU 内存分配的跟踪，记录了每个 GPU 的内存使用情况。

**时间管理**：

- 提供了函数用于测量自特定时间点以来的微秒数。

**获取当前设备 ID (`get_current_device_id`)**：

- 此函数调用 `cuCtxGetDevice` 来获取当前 CUDA 设备的 ID

**配置网络连接 (`configure_connection`)**：

- 从环境变量中读取 Pod 管理器的 IP 地址和端口号。
- 如果能够读取到端口号，它会解析并存储到 `pod_manager_port_list` 中，并更新当前 GPU 的数量。

**device 与调度器建立连接 (`establish_connection`)**：

- 为每个设备创建一个套接字，并尝试连接到 Pod 管理器的 IP 和端口

**device 与 Pod 管理器/调度器通信 (`communicate`)**：

- 该函数建立与特定设备相关的网络连接，发送请求并接收响应。
- 使用互斥锁确保一次只有一个线程进行通信。

**记录主机端同步调用并更新预测器统计 (`host_sync_call`)**：

- 记录主机端的同步调用，并使用预测器来记录开始和停止的时间点。

**获取 GPU 内存信息 (`get_gpu_memory_info`)**：

- 向 Pod 管理器发送请求，获取可用 GPU 内存信息。
- 返回值是一个包含剩余内存和内存限制的 pair。

**更新内存使用情况 (`update_memory_usage`)**：

- 向 Pod 管理器发送内存分配或释放的信息。

**估计完整 GPU kernel burst 运行时间 (`estimate_full_burst`)**：

- 该函数基于测量的内核运行时间和窗口期来估计一个完整的 GPU kernel burst 运行时间。如果测量的窗口期小于某个阈值，表示 GPU 正在积极使用，因此会增加估计的内核运行时间。

**从调度系统获取令牌 (`get_token_from_scheduler`)**：

- 向调度系统发送一个请求令牌的消息，以获得执行下一个 GPU 内核运行的时间配额。

**等待所有活动的内核完成 (`wait_cuda_kernels`)**：

- 这个函数循环等待所有正在运行的 CUDA 内核完成，同时更新超额使用统计。
- 使用 CUDA 事件来同步所有运行中的内核，然后更新超额使用时间。

**预处理和后处理 CUDA 函数调用**：

- `cuLaunchKernel_prehook` 和 `cuLaunchCooperativeKernel_prehook` 是在 CUDA 内核启动之前执行的预处理函数。这些函数负责检查和更新内核运行的时间配额，确保不会超过从调度系统获得的时间配额。
- `cuMemFree_prehook` 是在 CUDA 内存释放操作之前执行的预处理函数。它更新 GPU 内存使用情况，并将信息发送回调度系统。
- 内存销毁和释放的预处理 (`cuArrayDestroy_prehook`, `cuMipmappedArrayDestroy_prehook`)：调用 `cuMemFree_prehook` 来处理 CUDA 数组和 Mipmapped 数组的销毁
- 内存分配的预处理和后处理 (`cuMemAlloc_prehook`, `cuMemAlloc_posthook`)：
  - 预处理函数 `cuMemAlloc_prehook` 在内存分配之前检查是否有足够的剩余内存。如果请求的内存超过剩余内存，将返回内存不足错误。
  - 后处理函数 `cuMemAlloc_posthook` 在内存分配后更新内存使用情况，包括向后端发送内存使用更新和本地内存映射的更新。
- 特殊内存分配函数的预处理和后处*：
  - `cuMemAllocManaged_prehook`, `cuMemAllocManaged_posthook`, `cuMemAllocPitch_prehook`, `cuMemAllocPitch_posthook`, `cuArrayCreate_prehook`, `cuArrayCreate_posthook`, `cuArray3DCreate_prehook`, `cuArray3DCreate_posthook`, `cuMipmappedArrayCreate_prehook`, `cuMipmappedArrayCreate_posthook`：这些函数处理不同类型的 CUDA 内存分配请求，例如管理内存、带间距的内存分配、数组和三维数组的创建等。
  - 大多数函数在预处理阶段调用 `cuMemAlloc_prehook` 来检查内存，而在后处理阶段调用 `cuMemAlloc_posthook` 来更新内存使用情况。
- 同步和内存复制操作的后处理：
  - `cuCtxSynchronize_posthook`, `cuMemcpyAtoH_posthook`, `cuMemcpyDtoH_posthook`, `cuMemcpyHtoA_posthook`, `cuMemcpyHtoD_posthook`：这些函数在相应的 CUDA 操作（如同步和不同类型的内存复制）完成后被调用，主要用于记录主机端的同步调用。

**初始化函数 (`initialize`)**：

- 这个函数初始化了一些关键变量和结构，例如为每个 GPU 设置时间配额、配置网络连接、创建 CUDA 事件，以及启动用于跟踪过度使用的线程。
- 它还为 CUDA API 函数设置了预处理和后处理 hook ，这是通过更新 `hook_inf` 结构体中的 `preHooks` 和 `postHooks` 数组实现的。

**宏定义 (`CU_HOOK_GENERATE_INTERCEPT`)**：

- 这个宏用于生成函数拦截器，它包装了 CUDA API 函数，并在调用原始函数之前和之后执行预处理和后处理逻辑。
- 它使用 `pthread_once` 来确保 `initialize` 函数只被执行一次，然后通过 `real_dlsym` 动态获取原始 CUDA 函数的地址。
- 在调用原始函数之前，如果有预处理 hook，则先执行预处理逻辑；调用原始函数后，如果有后处理 hook 并且原始函数调用成功，则执行后处理逻辑。

**CUDA API 函数拦截器的生成**：

- 使用 `CU_HOOK_GENERATE_INTERCEPT` 宏为多个 CUDA API 函数生成拦截器

**内存信息查询 API 函数 (`cuDeviceTotalMem`, `cuMemGetInfo`)**：

- 这两个函数是 CUDA API 的一部分，用于获取设备总内存和可用内存信息。它们通过 `get_gpu_memory_info` 函数获取信息，并更新调用计数（如果处于调试模式）。